{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739bc240",
   "metadata": {},
   "source": [
    "## 1. Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da65b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import analyze_nifti_dimensions, show_slices_all_modalities\n",
    "from viz import get_bbox_from_mask_skimage, plot_images_with_bboxes\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "ROOT_MS_SHIFT = Path(\"/path/to/your/data/please/edit/me\")\n",
    "ROOT_MSLESSEG = Path(\"/path/to/your/data/please/edit/me\")\n",
    "\n",
    "# --- MS_Shift Configuration ---\n",
    "MS_SHIFT_SPLITS: Dict[str, Path] = {\n",
    "    \"Train\": ROOT_MS_SHIFT / \"Train\",\n",
    "    \"Test\": ROOT_MS_SHIFT / \"Test\",\n",
    "    \"Val\": ROOT_MS_SHIFT / \"Val\",\n",
    "}\n",
    "MS_SHIFT_MODALITIES: List[str] = [\"FLAIR\", \"T1CE\", \"T2\", \"PD\", \"T1\", \"gt\"]\n",
    "MS_SHIFT_SUFFIXES: List[str] = [\n",
    "    \"FLAIR_isovox.nii.gz\",\n",
    "    \"isovox_fg_mask.nii.gz\",  # foreground mask\n",
    "    \"T1CE_isovox.nii.gz\",\n",
    "    \"T2_isovox.nii.gz\",\n",
    "    \"gt_isovox.nii.gz\",\n",
    "    \"PD_isovox.nii.gz\",\n",
    "    \"T1_isovox.nii.gz\",\n",
    "]\n",
    "MS_SHIFT_GT_KEY = \"gt\"\n",
    "MS_SHIFT_IGNORE_KEYS = (\"isovox_fg_mask\",)\n",
    "\n",
    "# --- MSLesSeg Configuration ---\n",
    "MSLESSEG_SPLITS: Dict[str, Path] = {\n",
    "    \"train\": ROOT_MSLESSEG / \"train\",\n",
    "    \"test\": ROOT_MSLESSEG / \"test\",\n",
    "}\n",
    "MSLESSEG_MODALITIES: List[str] = [\"FLAIR\", \"T2\", \"T1\", \"MASK\"]\n",
    "\n",
    "MSLESSEG_TRAIN_SUFFIX_FORMAT = (\n",
    "    \"{ts}_{mod}.nii.gz\"  # ts (timestamp)=T1, T2... mod=FLAIR...\n",
    ")\n",
    "MSLESSEG_TEST_SUFFIX_FORMAT = \"{mod}.nii.gz\"\n",
    "MSLESSEG_MASK_SUFFIX = \"MASK.nii.gz\"\n",
    "MSLESSEG_GT_KEY = \"MASK\"\n",
    "\n",
    "NIFTI_FORMATS = (\".nii\", \".nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0b121",
   "metadata": {},
   "source": [
    "## 2. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63c0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice(img_3d: np.ndarray, slice_dim: int, slice_index: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts a 2D slice from a 3D array.\n",
    "\n",
    "    Args:\n",
    "        img_3d (np.ndarray): The 3D image data.\n",
    "        slice_dim (int): Dimension along which to slice (0, 1, or 2).\n",
    "        slice_index (int): Index of the slice to extract.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The extracted 2D slice..\n",
    "    \"\"\"\n",
    "    if not (0 <= slice_dim <= 2):\n",
    "        raise ValueError(f\"Invalid slice_dim: {slice_dim}. Must be 0, 1, or 2.\")\n",
    "    if not (0 <= slice_index < img_3d.shape[slice_dim]):\n",
    "        raise IndexError(\n",
    "            f\"slice_index {slice_index} out of bounds for dimension {slice_dim} with shape {img_3d.shape}\"\n",
    "        )\n",
    "\n",
    "    if slice_dim == 0:\n",
    "        return img_3d[slice_index, :, :]\n",
    "    elif slice_dim == 1:\n",
    "        return img_3d[:, slice_index, :]\n",
    "    else:\n",
    "        return img_3d[:, :, slice_index]\n",
    "\n",
    "\n",
    "def verify_dataset_structure(\n",
    "    split_paths: Dict[str, Path],\n",
    "    expected_suffixes: Union[List[str], Dict[str, str]],  # Список или формат-строка\n",
    "    modality_keys: List[str],\n",
    "    gt_key: str,\n",
    "    ignore_suffixes: Optional[Tuple[str, ...]] = None,\n",
    "    check_train_timepoints: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks directory structure and file naming for a single split of the dataset.\n",
    "\n",
    "    Args:\n",
    "        split_paths (Dict[str, Path]): Dictionary of {split_name: split_path}.\n",
    "        expected_suffixes (Union[List[str], Dict[str, str]]):\n",
    "            - For MS_Shift: List of expected file suffixes (after SubjectID_).\n",
    "            - For MSLesSeg: Dictionary with format strings for 'train' and 'test'\n",
    "            (e.g., {\"train\": \"{ts}_{mod}.nii.gz\", \"test\": \"{mod}.nii.gz\"}).\n",
    "        modality_keys (List[str]): List of expected modality keys (including gt_key).\n",
    "        gt_key (str): Key identifying the mask file.\n",
    "        ignore_suffixes (Optional[Tuple[str, ...]]): File suffixes to ignore when checking.\n",
    "        check_train_timepoints (bool): Flag for MSLesSeg to check subfolders T1, T2... in train.\n",
    "    \"\"\"\n",
    "    all_ok = True\n",
    "    for split_name, split_dir in split_paths.items():\n",
    "        logger.info(\n",
    "            f\"--- Verifying structure for split: {split_name} in {split_dir} ---\"\n",
    "        )\n",
    "        if not split_dir.is_dir():\n",
    "            logger.error(f\"Directory not found: {split_dir}\")\n",
    "            all_ok = False\n",
    "            continue\n",
    "\n",
    "        subject_dirs = sorted(\n",
    "            [d for d in split_dir.iterdir() if d.is_dir() and d.name.startswith(\"P\")]\n",
    "        )  # MSLesSeg: P*, MS_Shift: numeric\n",
    "        if (\n",
    "            not subject_dirs and split_name != \"Val\"\n",
    "        ):  # MS_Shift Validation may have a different structure\n",
    "            numeric_dirs = [\n",
    "                d for d in split_dir.iterdir() if d.is_dir() and d.name.isdigit()\n",
    "            ]\n",
    "\n",
    "            subject_dirs = sorted(numeric_dirs, key=lambda path_obj: int(path_obj.name))\n",
    "\n",
    "        if not subject_dirs:\n",
    "            logger.warning(f\"No subject directories found in {split_dir}.\")\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"Found {len(subject_dirs)} subject directories.\")\n",
    "\n",
    "        for subj_dir in subject_dirs:\n",
    "            subj_id = subj_dir.name\n",
    "            locations_to_check = [subj_dir]\n",
    "            is_train_mslesseg = check_train_timepoints and split_name == \"train\"\n",
    "\n",
    "            if is_train_mslesseg:\n",
    "                locations_to_check = [\n",
    "                    d\n",
    "                    for d in subj_dir.iterdir()\n",
    "                    if d.is_dir() and d.name.startswith(\"T\")\n",
    "                ]\n",
    "                if not locations_to_check:\n",
    "                    logger.warning(\n",
    "                        f\"MSLesSeg train subject {subj_id} has no timepoint subdirectories (T*).\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "            for loc_dir in locations_to_check:\n",
    "                loc_files = {\n",
    "                    f.name\n",
    "                    for f in loc_dir.iterdir()\n",
    "                    if f.is_file() and f.name.lower().endswith(NIFTI_FORMATS)\n",
    "                }\n",
    "                expected_files = set()\n",
    "\n",
    "                # Determine expected suffixes for the current location\n",
    "                current_suffixes = []\n",
    "                if isinstance(expected_suffixes, list):  # MS_Shift like\n",
    "                    current_suffixes = expected_suffixes\n",
    "                    prefix = f\"{subj_id}_\"\n",
    "                elif isinstance(expected_suffixes, dict):  # MSLesSeg like\n",
    "                    suffix_format = expected_suffixes.get(split_name)\n",
    "                    if suffix_format:\n",
    "                        if is_train_mslesseg:\n",
    "                            ts = loc_dir.name  # Timepoint like T1\n",
    "                            current_suffixes = [\n",
    "                                suffix_format.format(ts=ts, mod=mod)\n",
    "                                for mod in modality_keys\n",
    "                            ]\n",
    "                            prefix = f\"{subj_id}_\"\n",
    "                        else:  # Test split or flat train structure\n",
    "                            current_suffixes = [\n",
    "                                suffix_format.format(mod=mod)\n",
    "                                for mod in modality_keys\n",
    "                                if mod != gt_key\n",
    "                            ]\n",
    "                            # Add mask suffix separately if needed for test (usually not present)\n",
    "                            if (\n",
    "                                gt_key in modality_keys\n",
    "                            ):  # If mask *could* be expected (even if usually absent in test)\n",
    "                                current_suffixes.append(\n",
    "                                    suffix_format.format(mod=gt_key)\n",
    "                                )\n",
    "                            prefix = f\"{subj_id}_\"\n",
    "                    else:\n",
    "                        logger.error(\n",
    "                            f\"Suffix format string not found for split '{split_name}' in expected_suffixes dict.\"\n",
    "                        )\n",
    "                        all_ok = False\n",
    "                        continue\n",
    "                else:\n",
    "                    logger.error(\"Invalid format for expected_suffixes.\")\n",
    "                    all_ok = False\n",
    "                    continue\n",
    "\n",
    "                # Generate expected full file names\n",
    "                for suffix in current_suffixes:\n",
    "                    # Skip ignored suffixes\n",
    "                    if ignore_suffixes and any(\n",
    "                        ign_suf in suffix for ign_suf in ignore_suffixes\n",
    "                    ):\n",
    "                        continue\n",
    "                    expected_files.add(f\"{prefix}{suffix}\")\n",
    "\n",
    "                # Compare\n",
    "                missing_files = expected_files - loc_files\n",
    "                extra_files = loc_files - expected_files\n",
    "                # Ignore hidden files in extra_files\n",
    "                extra_files = {f for f in extra_files if not f.startswith(\".\")}\n",
    "\n",
    "                if missing_files:\n",
    "                    # Don't consider MASK/gt missing in test split if it is not required\n",
    "                    is_test_split = split_name == \"test\"\n",
    "                    truly_missing = set()\n",
    "                    for f in missing_files:\n",
    "                        if is_test_split and gt_key in f:\n",
    "                            continue\n",
    "                        truly_missing.add(f)\n",
    "\n",
    "                    if truly_missing:\n",
    "                        logger.warning(\n",
    "                            f\"Subject {subj_id} (in {loc_dir.name}): Missing files: {sorted(list(truly_missing))}\"\n",
    "                        )\n",
    "                        all_ok = False  # We consider it an error if something other than GT is missing in the test\n",
    "\n",
    "                if extra_files:\n",
    "                    logger.warning(\n",
    "                        f\"Subject {subj_id} (in {loc_dir.name}): Found extra/unexpected files: {sorted(list(extra_files))}\"\n",
    "                    )\n",
    "\n",
    "    if all_ok:\n",
    "        logger.info(\n",
    "            f\"Structure verification PASSED for splits: {list(split_paths.keys())}\"\n",
    "        )\n",
    "    else:\n",
    "        logger.error(\n",
    "            f\"Structure verification FAILED for splits: {list(split_paths.keys())}. See warnings above.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def analyze_mask_statistics(mask_filepath: Path) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Parses a single NIfTI segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        mask_filepath (Path): Path to NIfTI mask file.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Dict]: Dictionary with statistics (size, number of hits,\n",
    "                        percentage of hit voxels) or None on error.\n",
    "    \"\"\"\n",
    "    img_data = nib.load(mask_filepath).get_fdata()\n",
    "    if img_data is None:\n",
    "        return None\n",
    "\n",
    "    mask_data = img_data.astype(np.uint8)\n",
    "    total_voxels = mask_data.size\n",
    "    lesion_voxels = np.sum(mask_data > 0)\n",
    "    lesion_percentage = (lesion_voxels / total_voxels) * 100 if total_voxels > 0 else 0\n",
    "\n",
    "    # Counting the number of individual lesions (connected components)\n",
    "    labels, num_labels = measure.label(mask_data, connectivity=2, return_num=True)\n",
    "    num_lesions = num_labels  # num_labels includes background as 0\n",
    "\n",
    "    # Statistics on the size of lesions\n",
    "    region_props = measure.regionprops(labels)\n",
    "    lesion_sizes = [prop.area for prop in region_props]  # Area is number of voxels\n",
    "\n",
    "    stats = {\n",
    "        \"shape\": mask_data.shape,\n",
    "        \"total_voxels\": total_voxels,\n",
    "        \"lesion_voxels\": lesion_voxels,\n",
    "        \"lesion_percentage\": lesion_percentage,\n",
    "        \"num_lesions\": num_lesions,\n",
    "        \"lesion_sizes\": lesion_sizes,  # List of sizes of each lesion\n",
    "        \"mean_lesion_size\": np.mean(lesion_sizes) if lesion_sizes else 0,\n",
    "        \"median_lesion_size\": np.median(lesion_sizes) if lesion_sizes else 0,\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_intensity_distribution(img_filepath: Path, modality_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Loads a NIfTI image and plots a histogram of the voxel intensity distribution.\n",
    "\n",
    "    Args:\n",
    "        img_filepath (Path): Path to the NIfTI image file.\n",
    "        modality_name (str): Modality name for the plot title.\n",
    "    \"\"\"\n",
    "    img_data = nib.load(img_filepath).get_fdata()\n",
    "    if img_data is None:\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    # Exclude zero values ​​(background) for better visualization of tissue distribution\n",
    "    non_zero_voxels = img_data[img_data > 0].flatten()\n",
    "    if non_zero_voxels.size > 0:\n",
    "        sns.histplot(non_zero_voxels, bins=100, kde=True)\n",
    "        plt.title(f\"Intensity distribution for {modality_name} ({img_filepath.name})\")\n",
    "        plt.xlabel(\"Voxel intensity (excluding 0)\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        logger.warning(f\"Image {img_filepath.name} contains only zero values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74f9e6",
   "metadata": {},
   "source": [
    "## 3. EDA for MS_Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5907c8c",
   "metadata": {},
   "source": [
    "### Checking the Structure of MS_Shift Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18eca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all expected files are present for each subject in each split.\n",
    "verify_dataset_structure(\n",
    "    MS_SHIFT_SPLITS,\n",
    "    expected_suffixes=MS_SHIFT_SUFFIXES,\n",
    "    modality_keys=MS_SHIFT_MODALITIES,\n",
    "    gt_key=MS_SHIFT_GT_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1ba2a",
   "metadata": {},
   "source": [
    "### Image Dimension Analysis MS_Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what unique sizes of 3D volumes are found in the dataset.\n",
    "ms_shift_dims_train = analyze_nifti_dimensions(str(MS_SHIFT_SPLITS[\"Train\"]))\n",
    "ms_shift_dims_val = analyze_nifti_dimensions(str(MS_SHIFT_SPLITS[\"Val\"]))\n",
    "ms_shift_dims_test = analyze_nifti_dimensions(str(MS_SHIFT_SPLITS[\"Test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788eac6",
   "metadata": {},
   "source": [
    "### MS_Shift Slice Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9753969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select a random subject from the split\n",
    "split = \"Train\"\n",
    "subj_ids = [\n",
    "    d.name for d in MS_SHIFT_SPLITS[split].iterdir() if d.is_dir() and d.name.isdigit()\n",
    "]\n",
    "idx = random.choice(subj_ids)\n",
    "slice_index_axial = 121\n",
    "# idx = str(21)\n",
    "\n",
    "logger.info(f\"Visualizing modalities for MS_Shift split {split}: idx {idx}\")\n",
    "show_slices_all_modalities(\n",
    "    str(MS_SHIFT_SPLITS[split] / idx), slice_idx=slice_index_axial, dim=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fefec",
   "metadata": {},
   "source": [
    "### MS_Shift Pixel/Voxel Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d342ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subject from the split\n",
    "split = \"Train\"\n",
    "subj_ids = [\n",
    "    d.name for d in MS_SHIFT_SPLITS[split].iterdir() if d.is_dir() and d.name.isdigit()\n",
    "]\n",
    "random_idx = random.choice(subj_ids)\n",
    "modality = MS_SHIFT_MODALITIES[0]  # [\"FLAIR\", \"T1CE\", \"T2\", \"PD\", \"T1\", \"gt\"]\n",
    "subj_dir = MS_SHIFT_SPLITS[split] / random_idx\n",
    "img_path = next(subj_dir.glob(f\"{random_idx}_{modality}*.nii.gz\"), None)\n",
    "gt_path = next(subj_dir.glob(f\"{random_idx}_gt*.nii.gz\"), None)\n",
    "gt_data = nib.load(gt_path).get_fdata()\n",
    "\n",
    "if img_path:\n",
    "    logger.info(f\"\\n--- Analyzing {split} {modality}: {img_path.name} ---\")\n",
    "    img_data = nib.load(img_path).get_fdata()\n",
    "    if img_data is not None:\n",
    "        print(f\"Shape: {img_data.shape}\")\n",
    "        print(f\"Min: {img_data.min():.2f}, Max: {img_data.max():.2f}\")\n",
    "        print(f\"Mean: {img_data.mean():.2f}, Std: {img_data.std():.2f}\")\n",
    "        plot_intensity_distribution(img_path, modality)\n",
    "    else:\n",
    "        logger.error(f\"Could not load {split} {modality} data for analysis.\")\n",
    "else:\n",
    "    logger.warning(f\"{modality} file not found for subject {img_path}.\")\n",
    "\n",
    "if gt_path:\n",
    "    logger.info(f\"\\n--- Analyzing GT Mask: {split} {gt_path.name} ---\")\n",
    "    mask_stats = analyze_mask_statistics(gt_path)\n",
    "    if mask_stats:\n",
    "        print(f\"Shape: {mask_stats['shape']}\")\n",
    "        print(f\"Total Voxels: {mask_stats['total_voxels']}\")\n",
    "        print(f\"Lesion Voxels: {mask_stats['lesion_voxels']}\")\n",
    "        print(f\"Lesion Percentage: {mask_stats['lesion_percentage']:.4f}%\")\n",
    "        print(f\"Number of Lesions (connected components): {mask_stats['num_lesions']}\")\n",
    "        if mask_stats[\"lesion_sizes\"]:\n",
    "            print(\n",
    "                f\"Lesion Sizes (voxels): Min={min(mask_stats['lesion_sizes'])}, Max={max(mask_stats['lesion_sizes'])}, Mean={mask_stats['mean_lesion_size']:.2f}, Median={mask_stats['median_lesion_size']:.1f}\"\n",
    "            )\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.histplot(mask_stats[\"lesion_sizes\"], bins=50)\n",
    "            plt.title(f\"Lesion Size Distribution (voxels) - {split} {gt_path.name}\")\n",
    "            plt.xlabel(\"Lesion Size (voxels)\")\n",
    "            plt.ylabel(\"Number\")\n",
    "            plt.yscale(\"log\")  # Use a logarithmic scale for sizes\n",
    "            plt.show()\n",
    "    else:\n",
    "        logger.error(\"Could not load GT data for analysis.\")\n",
    "else:\n",
    "    logger.warning(f\"GT mask file not found for subject {gt_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bded22e",
   "metadata": {},
   "source": [
    "### Visualization of Bounding Boxes MS_Shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f515aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subject from the split\n",
    "# split = \"Train\"\n",
    "# subj_ids = [d.name for d in MS_SHIFT_SPLITS[split].iterdir() if d.is_dir() and d.name.isdigit()]\n",
    "# random_idx = random.choice(subj_ids)\n",
    "# modality = MS_SHIFT_MODALITIES[0]  # [\"FLAIR\", \"T1CE\", \"T2\", \"PD\", \"T1\", \"gt\"]\n",
    "# subj_dir = MS_SHIFT_SPLITS[split] / random_idx\n",
    "# img_path = next(subj_dir.glob(f\"{random_idx}_{modality}*.nii.gz\"), None)\n",
    "# gt_path = next(subj_dir.glob(f\"{random_idx}_gt*.nii.gz\"), None)\n",
    "# gt_data = nib.load(gt_path).get_fdata()\n",
    "\n",
    "slice_dim_vis = 2\n",
    "slice_idx_vis = 115\n",
    "\n",
    "if 0 <= slice_idx_vis < img_data.shape[slice_dim_vis]:\n",
    "    img_slice = get_slice(img_data, slice_dim_vis, slice_idx_vis)\n",
    "    mask_slice = get_slice(gt_data, slice_dim_vis, slice_idx_vis)\n",
    "\n",
    "    bboxes_pixels = get_bbox_from_mask_skimage(mask_slice)\n",
    "    print(\n",
    "        f\"\\nBounding boxes found on on split {split} slice {slice_idx_vis} (dim {slice_dim_vis}): {len(bboxes_pixels)}\"\n",
    "    )\n",
    "\n",
    "    plot_images_with_bboxes(\n",
    "        images=[img_slice, mask_slice],\n",
    "        bboxes_list=[bboxes_pixels, bboxes_pixels],  # Показываем bbox'ы на обоих\n",
    "        titles=[\n",
    "            f\"{modality} Slice {slice_idx_vis}\",\n",
    "            f\"Mask Slice {slice_idx_vis}/ BBoxes\",\n",
    "        ],\n",
    "        main_title=f\"Split {split} Idx {random_idx} - Slice {slice_idx_vis} - Dim {slice_dim_vis}\",\n",
    "        cols=2,\n",
    "    )\n",
    "else:\n",
    "    logger.warning(f\"Slice index {slice_idx_vis} is out of bounds for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ed3e4",
   "metadata": {},
   "source": [
    "## 4. EDA for MSLesSeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2f23c9",
   "metadata": {},
   "source": [
    "### Checking the Structure of MS_Shift Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all expected files are present for each subject in each split.\n",
    "mslesseg_suffix_formats = {\n",
    "    \"train\": MSLESSEG_TRAIN_SUFFIX_FORMAT,\n",
    "    \"test\": MSLESSEG_TEST_SUFFIX_FORMAT,\n",
    "}\n",
    "verify_dataset_structure(\n",
    "    {\"train\": MSLESSEG_SPLITS[\"train\"]},\n",
    "    expected_suffixes=mslesseg_suffix_formats,\n",
    "    modality_keys=MSLESSEG_MODALITIES,\n",
    "    gt_key=MSLESSEG_GT_KEY,\n",
    "    check_train_timepoints=True,  # Important for MSLesSeg train\n",
    ")\n",
    "# Проверка Test\n",
    "verify_dataset_structure(\n",
    "    {\"test\": MSLESSEG_SPLITS[\"test\"]},\n",
    "    expected_suffixes=mslesseg_suffix_formats,\n",
    "    modality_keys=MSLESSEG_MODALITIES,\n",
    "    gt_key=MSLESSEG_GT_KEY,\n",
    "    check_train_timepoints=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ec7db",
   "metadata": {},
   "source": [
    "### Image Dimension Analysis MSLesSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac496a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what unique sizes of 3D volumes are found in the dataset.\n",
    "mslesseg_dims_train = analyze_nifti_dimensions(str(MSLESSEG_SPLITS[\"train\"]))\n",
    "mslesseg_dims_test = analyze_nifti_dimensions(str(MSLESSEG_SPLITS[\"test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33199c4",
   "metadata": {},
   "source": [
    "### MSLesSeg Slice Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b654962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subject from the split\n",
    "split = \"train\"\n",
    "subj_ids_msl = [\n",
    "    d.name\n",
    "    for d in MSLESSEG_SPLITS[split].iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"P\")\n",
    "]\n",
    "idx = random.choice(subj_ids_msl)\n",
    "# idx = str(21)\n",
    "timepoint_dirs = [\n",
    "    d\n",
    "    for d in (MSLESSEG_SPLITS[split] / idx).iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"T\")\n",
    "]\n",
    "if timepoint_dirs:\n",
    "    random_timepoint_dir = random.choice(timepoint_dirs)\n",
    "    logger.info(\n",
    "        f\"Visualizing modalities for MSLesSeg split {split}: {idx}, Timepoint: {random_timepoint_dir.name}\"\n",
    "    )\n",
    "else:\n",
    "    logger.warning(f\"No timepoint directories found for MSLesSeg split {split} {idx}.\")\n",
    "\n",
    "slice_index_axial = 78\n",
    "show_slices_all_modalities(\n",
    "    (str(random_timepoint_dir)), slice_idx=slice_index_axial, dim=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baec280",
   "metadata": {},
   "source": [
    "### MSLesSeg Pixel/Voxel Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subject from the split\n",
    "split = \"train\"\n",
    "subj_ids_msl = [\n",
    "    d.name\n",
    "    for d in MSLESSEG_SPLITS[split].iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"P\")\n",
    "]\n",
    "idx = random.choice(subj_ids_msl)\n",
    "# idx = str(21)\n",
    "timepoint_dirs = [\n",
    "    d\n",
    "    for d in (MSLESSEG_SPLITS[split] / idx).iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"T\")\n",
    "]\n",
    "if timepoint_dirs:\n",
    "    random_timepoint_dir = random.choice(timepoint_dirs)\n",
    "    logger.info(\n",
    "        f\"Visualizing modalities for MSLesSeg split {split}: {idx}, Timepoint: {random_timepoint_dir.name}\"\n",
    "    )\n",
    "else:\n",
    "    logger.warning(f\"No timepoint directories found for MSLesSeg split {split} {idx}.\")\n",
    "\n",
    "\n",
    "tp_id = random_timepoint_dir.name\n",
    "modality = MSLESSEG_MODALITIES[0]  # [\"FLAIR\", \"T2\", \"T1\", \"MASK\"]\n",
    "img_path_msl = next(random_timepoint_dir.glob(f\"{idx}_{tp_id}_{modality}.nii.gz\"), None)\n",
    "mask_path_msl = next(random_timepoint_dir.glob(f\"{idx}_{tp_id}_MASK.nii.gz\"), None)\n",
    "\n",
    "if img_path_msl:\n",
    "    logger.info(f\"\\n--- Analyzing {split} {modality}: {img_path_msl.name} ---\")\n",
    "    plot_intensity_distribution(img_path_msl, modality)\n",
    "else:\n",
    "    logger.warning(f\"{modality} file not found for {idx}/{tp_id}.\")\n",
    "\n",
    "if mask_path_msl:\n",
    "    logger.info(f\"\\n--- Analyzing GT Mask: {split} {mask_path_msl.name} ---\")\n",
    "    mask_stats_msl = analyze_mask_statistics(mask_path_msl)\n",
    "    if mask_stats_msl:\n",
    "        print(f\"Shape: {mask_stats_msl['shape']}\")\n",
    "        print(f\"Total Voxels: {mask_stats_msl['total_voxels']}\")\n",
    "        print(f\"Lesion Voxels: {mask_stats_msl['lesion_voxels']}\")\n",
    "        print(f\"Lesion Percentage: {mask_stats_msl['lesion_percentage']:.4f}%\")\n",
    "        print(\n",
    "            f\"Number of Lesions (connected components): {mask_stats_msl['num_lesions']}\"\n",
    "        )\n",
    "        if mask_stats_msl[\"lesion_sizes\"]:\n",
    "            print(\n",
    "                f\"Lesion Sizes (voxels): Min={min(mask_stats_msl['lesion_sizes'])}, Max={max(mask_stats_msl['lesion_sizes'])}, Mean={mask_stats_msl['mean_lesion_size']:.2f}, Median={mask_stats_msl['median_lesion_size']:.1f}\"\n",
    "            )\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            sns.histplot(mask_stats_msl[\"lesion_sizes\"], bins=50)\n",
    "            plt.title(f\"Lesion Size Distribution (voxels) - {mask_path_msl.name}\")\n",
    "            plt.xlabel(\"Lesion Size (voxels)\")\n",
    "            plt.ylabel(\"Number\")\n",
    "            plt.yscale(\"log\")  # Use a logarithmic scale for sizes\n",
    "            plt.show()\n",
    "    else:\n",
    "        logger.error(\"Could not load GT data for MSLesSeg analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04ff3b",
   "metadata": {},
   "source": [
    "### Visualization of Bounding Boxes MSLesSeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subject from the split\n",
    "split = \"train\"\n",
    "subj_ids_msl = [\n",
    "    d.name\n",
    "    for d in MSLESSEG_SPLITS[split].iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"P\")\n",
    "]\n",
    "idx = random.choice(subj_ids_msl)\n",
    "# idx = str(21)\n",
    "timepoint_dirs = [\n",
    "    d\n",
    "    for d in (MSLESSEG_SPLITS[split] / idx).iterdir()\n",
    "    if d.is_dir() and d.name.startswith(\"T\")\n",
    "]\n",
    "if timepoint_dirs:\n",
    "    random_timepoint_dir = random.choice(timepoint_dirs)\n",
    "    logger.info(\n",
    "        f\"Visualizing modalities for MSLesSeg split {split}: {idx}, Timepoint: {random_timepoint_dir.name}\"\n",
    "    )\n",
    "else:\n",
    "    logger.warning(f\"No timepoint directories found for MSLesSeg split {split} {idx}.\")\n",
    "\n",
    "tp_id = random_timepoint_dir.name\n",
    "modality = MSLESSEG_MODALITIES[0]  # [\"FLAIR\", \"T2\", \"T1\", \"MASK\"]\n",
    "img_path_msl = next(random_timepoint_dir.glob(f\"{idx}_{tp_id}_{modality}.nii.gz\"), None)\n",
    "mask_path_msl = next(random_timepoint_dir.glob(f\"{idx}_{tp_id}_MASK.nii.gz\"), None)\n",
    "img_data_msl = nib.load(img_path_msl).get_fdata()\n",
    "mask_data_msl = nib.load(mask_path_msl).get_fdata()\n",
    "\n",
    "slice_dim_vis = 2\n",
    "slice_idx_vis = 128\n",
    "\n",
    "if 0 <= slice_idx_vis < img_data_msl.shape[slice_dim_vis]:\n",
    "    img_slice = get_slice(img_data_msl, slice_dim_vis, slice_idx_vis)\n",
    "    mask_slice = get_slice(mask_data_msl, slice_dim_vis, slice_idx_vis)\n",
    "\n",
    "    bboxes_pixels = get_bbox_from_mask_skimage(mask_slice)\n",
    "    print(\n",
    "        f\"\\nBounding boxes found on split {split} slice {slice_idx_vis} (dim {slice_dim_vis}): {len(bboxes_pixels)}\"\n",
    "    )\n",
    "\n",
    "    plot_images_with_bboxes(\n",
    "        images=[img_slice, mask_slice],\n",
    "        bboxes_list=[bboxes_pixels, bboxes_pixels],\n",
    "        titles=[\n",
    "            f\"{modality} Slice {slice_idx_vis}\",\n",
    "            f\"Mask Slice {slice_idx_vis}/ BBoxes\",\n",
    "        ],\n",
    "        main_title=f\"Split {split} Idx {random_idx} - Slice {slice_idx_vis} - Dim {slice_dim_vis}\",\n",
    "        cols=2,\n",
    "    )\n",
    "else:\n",
    "    logger.warning(f\"Slice index {slice_idx_vis} is out of bounds for visualization.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
